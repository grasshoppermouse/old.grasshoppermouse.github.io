<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.30" />


<title>The replication crisis: our statistics don&#39;t suck, our theories do - Ed Hagen</title>
<meta property="og:title" content="The replication crisis: our statistics don&#39;t suck, our theories do - Ed Hagen">



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="200"
         height="300"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="http://anthro.vancouver.wsu.edu/faculty/hagen/">Ed Hagen@WSU</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">8 min read</span>
    

    <h1 class="article-title">The replication crisis: our statistics don&#39;t suck, our theories do</h1>

    
    <span class="article-date">2018/01/16</span>
    

    <div class="article-content">
      <blockquote>
<p>Arthur: <em>Brother Maynard! Bring up the Holy Hand Grenade!….How does it, um– how does it work?</em></p>
</blockquote>
<blockquote>
<p>Second Brother: <em>And the Lord spake, saying, “First shalt thou take out the Holy Pin. Then, shalt thou count to three. No more. No less. Three shalt be the number thou shalt count, and the number of the counting shall be three. Four shalt thou not count, nor either count thou two, excepting that thou then proceed to three. Five is right out.”</em></p>
</blockquote>
<blockquote>
<p><a href="https://www.youtube.com/watch?v=xOrgLj9lOwk">Monty Python and the Holy Grail</a></p>
</blockquote>
<hr />
<p>Most social scientists test a substantive hypothesis, which we will call <span class="math inline">\(H_1\)</span>, by instead testing a null hypothesis, <span class="math inline">\(H_0\)</span>, which is usually something like “the mean of X equals 0” or “the correlation of X and Y equals 0.” If the probability of the data<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> under <span class="math inline">\(H_0\)</span> is low (e.g., <span class="math inline">\(p &lt; 0.05\)</span>), the researcher rejects <span class="math inline">\(H_0\)</span>, which is taken as evidence in favor of <span class="math inline">\(H_1\)</span>.</p>
<p>This approach, termed <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">null hypothesis significance testing</a> (NHST), has been subjected to scathing criticism. In the social sciences, for example, we know <span class="math inline">\(H_0\)</span> is false before we collect a single data point — the mean of X is never exactly 0, the correlation of two variables is never exactly 0, and so forth. Hence, the rejection of such a null, which <a href="http://dx.doi.org/10.1037/0003-066X.49.12.997">Cohen (1994)</a> termed a “nil” hypothesis, just depends on sample size:</p>
<blockquote>
<p><em>Thus far, I have been considering <span class="math inline">\(H_0\)</span>’s in their most general sense–as propositions about the state of affairs in a population, more particularly, as some specified value of a population parameter. Thus, “the population mean difference is 4” may be an <span class="math inline">\(H_0\)</span>, as may be “the proportion of males in this population is .75” and “the correlation in this population is .20.” But as almost universally used, the null in <span class="math inline">\(H_0\)</span> is taken to mean nil, zero….My work in power analysis led me to realize that the nil hypothesis is always false.</em></p>
</blockquote>
<p>Further, the rejection of a nil <span class="math inline">\(H_0\)</span> (which we already know to be false) is exceedingly weak evidence in favor of our pet hypothesis, <span class="math inline">\(H_1\)</span>. First, it is also probably consistent with many other hypotheses. Worse, if <span class="math inline">\(H_1\)</span> predicts, e.g., the mean of X is greater than 0, the chance of being right is 50-50. Even with this incredibly weak standard, lots of social science studies <a href="http://science.sciencemag.org/content/349/6251/aac4716">don’t replicate</a>.</p>
<p>We social scientists might be forgiven for concluding that NHST is deeply flawed. We would be wrong. The problem, instead, is our weak theories.</p>
<p>In the natural sciences, such as physics and chemistry, theories typically predict numerical values for various parameters. Sometimes the predicted value might be 0. Under Einstein’s theory of <a href="https://en.wikipedia.org/wiki/Special_relativity">special relativity</a>, for instance, the speed of light in the direction of the earth’s motion <a href="https://en.wikipedia.org/wiki/Michelson–Morley_experiment">will not differ</a> from the speed of light perpendicular to the earth’s motion. Other times, the predicted values are different from 0. Einstein’s theory of <a href="">general relativity</a>, for example, predicts that the sun will bend star light by a <a href="https://en.wikipedia.org/wiki/Tests_of_general_relativity">specific (non-zero) amount</a>. In either case, the predicted value is a substantive <span class="math inline">\(H_0\)</span> (not a nil) that can be meaningfully tested with NHST.</p>
<p>Unlike rejecting a nil, which social scientists usually take as evidence supporting their theory, rejecting a substantive <span class="math inline">\(H_0\)</span> <em>rejects</em> the theory! If the difference of the speed of light in one direction vs. another is greater than 0 <span class="math inline">\((p &lt; 3 \times 10^{-7})\)</span>, then special relativity is wrong!<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> If the sun bends light more or less than the predicted amount <span class="math inline">\((p &lt; 3 \times 10^{-7})\)</span> then general relativity is wrong!<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> In the natural sciences, NHST is often a powerful tool to <em>challenge</em> theories, not support them (see Figure 1).</p>
<div class="figure"><span id="fig:NHST"></span>
<img src="/post/2018-01-16-the-replication-crisis-our-statistics-don-t-suck-our-theories-do_files/figure-html/NHST-1.png" alt="Testing nils vs. substantive nulls. Black vertical line: null. Red vertical line: mean of data. **A**: Rejecting the nil that the mean = 0 is taken as support for a theory predicting that the mean has some value &gt; 0. **B**: Rejecting the substantive null that the mean = 0 rejects the theory. **C**: Failing to reject the substantive null that the mean = 3 fails to reject the theory. All data simulated." width="672" />
<p class="caption">
Figure 1: Testing nils vs. substantive nulls. Black vertical line: null. Red vertical line: mean of data. <strong>A</strong>: Rejecting the nil that the mean = 0 is taken as support for a theory predicting that the mean has some value &gt; 0. <strong>B</strong>: Rejecting the substantive null that the mean = 0 rejects the theory. <strong>C</strong>: Failing to reject the substantive null that the mean = 3 fails to reject the theory. All data simulated.
</p>
</div>
<p>Successfully challenging a theory, i.e., falsifying it, is an essential step toward developing a more correct theory.</p>
<p>This critical difference in the use of NHST in the natural vs. social sciences was pointed out by Paul Meehl in <a href="https://doi.org/10.1086/288135">1967</a>:</p>
<blockquote>
<p><em>Because physical theories typically predict numerical values, an improvement in experimental precision reduces the tolerance range and hence increases corroborability. In most psychological research, improved power of a statistical design leads to a prior probability approaching 1⁄2 of finding a significant difference in the theoretically predicted direction. Hence the corroboration yielded by “success” is very weak, and becomes weaker with increased precision. “Statistical significance” plays a logical role in psychology precisely the reverse of its role in physics.</em></p>
</blockquote>
<p>Most theories in the social sciences, including my own, are so weak that they can only predict that a value will be positive or negative, nothing more (e.g., Figure 1A). Such vague predictions make it harder to falsify these theories, therefore impeding development of better theories.</p>
<p>Yet it is certainly possible to develop social science theories that predict specific values, and thus expose themselves to meaningful challenges with NHST.</p>
<p>In my own work, for example, I recently missed an opportunity to do better science by following standard practice and testing a nil, when I could, and should, have also tested a substantive null. Aaron Lightner, Pat Barclay and I conducted a classic framing effect study in which we predicted that participants would make different monetary offers in an ultimatum game if it was framed as a currency exchange than if it was “unframed.” We set up our statistical test in the standard social science way. <span class="math inline">\(H_0\)</span> was a “nil”: <em>no difference in mean offers in the framed vs. unframed condition</em>. Surprise, surprise, we could reject the nil <span class="math inline">\((p = 1.8 \times 10^{-31})\)</span>, and therefore conclude that there was a difference in mean offers. <a href="http://dx.doi.org/10.1098/rsos.170543">Publication</a>!</p>
<p>I am disappointed in myself<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>, however, because we could have put our theory to a much more severe test by proposing a substantive <span class="math inline">\(H_0\)</span>. In our study, participants self-reported what they thought was a fair offer, and they also made actual monetary offers. Our scientific (not statistical) hypothesis was that actual offers would match self-reported fair offers. These, in turn, would match a cultural norm for offers in currency exchange that differed from offers usually seen in the ultimatum game. If a participant reported that 3% was a fair offer, for instance, then he or she should have offered 3%.</p>
<p>As our substantive <span class="math inline">\(H_0\)</span>, we therefore should have proposed this: <em>There will be no difference between actual offers and self-reported fair offers</em>. If we had, we would have found that the probability of our data under such an <span class="math inline">\(H_0\)</span> was very small<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>, leading us to reject <span class="math inline">\(H_0\)</span>, and therefore to reject our theory. Specifically, our data showed that although many actual offers were exactly, or very close to, self-reported fair offers (dots that fall on, or close to, the diagonal line), as our theory predicted, many other actual offers differed substantially from self-reported fair offers (dots that are far from the diagonal line), contrary to our prediction:</p>
<div class="figure"><span id="fig:fairvsactual"></span>
<img src="/images/F11.large.jpg" alt="Self-reported fair offers vs. actual offers in a framed ultimatum game experiment. There were two framed conditions: banker and customer. From [Lightner et al. 2017](http://dx.doi.org/10.1098/rsos.170543)."  />
<p class="caption">
Figure 2: Self-reported fair offers vs. actual offers in a framed ultimatum game experiment. There were two framed conditions: banker and customer. From <a href="http://dx.doi.org/10.1098/rsos.170543">Lightner et al. 2017</a>.
</p>
</div>
<p>We don’t even need to compute a p-value to see that we can reject our substantive <span class="math inline">\(H_0\)</span>. Our scientific theory is wrong.</p>
<p>Rejecting a theory is cause for excitement, however, not despair. If a physicist did an experiment that convincingly rejected the null that the speed of light in a vacuum is the same in all inertial frames of reference, she would set off an explosion of research in her discipline and end up with a Nobel Prize.</p>
<p>Our study confirmed our prediction that offers in the framed conditions would deviate substantially from the unframed condition. But, contrary to our prediction, it also found that many participants said that it would be fair to offer X, but then made a very different offer. Why? Great question for a new study!</p>
<p>In the social sciences we need more “Holy Hand Grenade” theories — theories that do not simply make the very weak prediction that, e.g., <span class="math inline">\(\bar{X}&gt;0\)</span>, which barely deserves to be called a prediction, but instead predict, e.g., that the number shall be three, no more, no less. Such theories can be subjected to severe tests (i.e., falsified) using NHST. Rejecting a substantive <span class="math inline">\(H_0 = 3\)</span>, or failing to reject it, would then represent real scientific progress, not the flip of a coin.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>More precisely, for some test statistic <span class="math inline">\(z\)</span>, the p-value is the probability of finding a value of <span class="math inline">\(z\)</span> equal to or more extreme than that observed, under the assumption that <span class="math inline">\(H_0\)</span> is true.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>In a recent example, the OPERA experiment <a href="https://en.wikipedia.org/wiki/Faster-than-light_neutrino_anomaly">mistakenly observed</a> neutrinos traveling faster than light.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Physicists usually demand much smaller p-values than social scientists, e.g., the <a href="https://blogs.scientificamerican.com/observations/five-sigmawhats-that/"><span class="math inline">\(5\sigma\)</span> rule</a>.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>This is no knock on my graduate student Aaron Lightner, nor on our collaborator Pat Barclay, both of whom did fantastic work on this study. I just wish I had this idea before we published the paper.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>To compute confidence intervals, we would need to estimate the precision of our measurements, e.g., how closely do self-reported fair offers correspond to participants’ actual beliefs about fair offers? For a detailed example of parameter estimation for a simple physics problem, see <a href="https://doi.org/10.1137/130929230">Aguilar et al. 2015</a>.<a href="#fnref5">↩</a></p></li>
</ol>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//grasshoppermouse.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-59181618-1', 'auto');
ga('send', 'pageview');
</script>

  </body>
</html>

